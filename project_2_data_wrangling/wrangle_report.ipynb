{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GATHERING AND GETTING TO KNOW THE DATASET \n",
    "For this project, three different datasets were gathered.\n",
    "\n",
    "    First was the enhanced  tweets archive of the 'we rate dogs' twitter page that was sent to the instructor and provided as a csv file in the classroom. it contains 2356 rows and 17 columns. 7 of these columns were extracted from the text column which is why it referred to as 'enhanced'. This dataset holds information about each tweet's id, text, source, url timeatamp and if it was a reply or retweet. It was downloaded directly from the classroom, uploaded to my jupyter notebook's directory and loaded into a dataframe named df_archive\n",
    "\n",
    "    The second dataset was an image prediction tsv file that was provided by the project instructor. it contains prediction about the breed of the dog present in each tweet's images. It contained 3 predictions, their respective confidence level and wether each prediction was a dog or not, for one image each out of the images present for 2075 of the tweets in the archive table. It was downloaded programmatically through a link provided in the classroom also and saved into a dataframe called df_images.\n",
    "\n",
    "    The third dataset was additional information about each tweet scraped from the twitter api in json format saved in a txt file provided by the project instructor. The retweet count and likes count for each tweet was then extected from this file and saved to a dataframe named likes_df \n",
    "\n",
    "# ASSESSING THE DATASETS \n",
    "All three dataframes were assessed visually and programmatically to understand what i'm working with and to look out for quality and tidiness issues and at the end, the following issues were discovered \n",
    "\n",
    "**Quality issues**\n",
    "1. rating denominator column in the twitter archive has value other than 10, which is the standard dog rating according to the we rate dogs rating system\n",
    "\n",
    "2. some tweets in the twitter archive dataframe are duplicates of other tweet as indicated in the retweet status id column\n",
    "\n",
    "3. missing values in the name column in the archive dataset are represented with 'none'\n",
    "\n",
    "4. timestamp column in the archive dataset is in string data type\n",
    "\n",
    "5. inaccurate values in the name column in the archive dataset eg 'a'\n",
    "\n",
    "6. 'retweeted_status_timestamp' column in the archive dataset is in strings datatype instead of datetime\n",
    "\n",
    "7. 'None' values in doggo pupper floofer and puppo columns are inaccurate representations\n",
    "\n",
    "8. some column names in the image prediction table are not descriptive enough\n",
    "\n",
    " **Tidiness issues**\n",
    "1.  dog stage is represented in multiple columns in the archive dataset \n",
    "\n",
    "2. relevant columns from all tables should be merged to form a single table\n",
    "\n",
    "\n",
    "# CLEANING DISCOVERED ISSUES \n",
    "      Copies of all three dataframes were made in other to preserve the original data and then cleaning was performed on the copy dataframes.\n",
    "      All quality issues discovered were solved first using the define-code-test approach. some of the functions used includes pd.to_datetime(), str.replace() and rename()\n",
    "      Tidiness issues were then solved using functions like df.drop(), + operator to conctenate columns and merge() to merge all three tables together. \n",
    "      \n",
    "      \n",
    " # FINAL RESULT \n",
    " This conluded my data wrangling effort and at the end i was left with a cleaned master dataset containing 1994 tweets in 13 columns holding all needed information about each tweet from basic tweet information to dog breed prediction to dog ranking and bio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
